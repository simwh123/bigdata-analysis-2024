{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝 실습\n",
    "\n",
    "### 텍스트 마이닝\n",
    "\n",
    "#### 데이터 수집\n",
    "\n",
    "##### 네이버 코로나 뉴스로 감성분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 라이브러리 등록\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/코로나_naver_news.json', encoding = 'utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 한글 이외의 것 다 제거하는 작업\n",
    "dfData['title'] = dfData['title'].apply(lambda x: re.sub(r'[^가-힣|ㄱ-]+',' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData['description'] = dfData['description'].apply(lambda x: re.sub(r'[^가-힣|ㄱ-]+',' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData[['title','pDate','description']].to_excel('./data/코로나뉴스_전처리.xlsx',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData = pd.read_excel('./data/코로나뉴스_전처리.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 감성분석 모델 재구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 훈련용 데이터 가져오기\n",
    "dfNsmcTrain = pd.read_csv('../day12/data/ratings_train.txt',engine='python', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNsmcTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNsmcTrain = dfNsmcTrain[dfNsmcTrain['document'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 한글이외에 다 제거\n",
    "dfNsmcTrain['document'] = dfNsmcTrain['document'].apply(lambda x: re.sub(r'[^가-힣|ㄱ-]+', ' ' , x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 한글 제거 후에 다시 document가 빈 row를 제거\n",
    "dfNsmcTrain = dfNsmcTrain[dfNsmcTrain['document'] != ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 벡터화 , 로지스틱회귀 모듈 등록\n",
    "import konlpy\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oktToken(text):\n",
    "    tokens = okt.morphs(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 벡터화 객체 생성\n",
    "tfidf = TfidfVectorizer(tokenizer=oktToken, ngram_range=(1,2), min_df=3,max_df=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.fit(dfNsmcTrain['document'])\n",
    "nsmc_train_tfidf = tfidf.transform(dfNsmcTrain['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 로지스틱회귀 모델 생성\n",
    "model = LogisticRegression(random_state=0, C=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(nsmc_train_tfidf,dfNsmcTrain['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 네이버 뉴스 타이틀로 감성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석할 데이터의 백터화\n",
    "data_title_tfidf = tfidf.transform(dfData['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감성분석(로지스틱회귀)\n",
    "title_predict = model.predict(data_title_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감성분석 결과 DF 저장\n",
    "dfData['title_label'] = title_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명도 동일하게 감성분석\n",
    "data_desc_tfidf = tfidf.transform(dfData['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감성분석\n",
    "dfData['description_label'] = model.predict(data_desc_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.to_excel('./data/코로나뉴스_감성분석_결과.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 시각화 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResult = pd.read_excel('./data/코로나뉴스_감성분석_결과.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResult.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타이틀의 감성별 갯수\n",
    "dfResult['title_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기사 내용의 감성별 갯수\n",
    "dfResult['description_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍정적 결과와 부정적 결과를 분리\n",
    "column_names = dfResult.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names.remove('pDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 DF생성\n",
    "dfPositiveData = pd.DataFrame(columns=column_names)\n",
    "dfNegativeData = pd.DataFrame(columns=column_names)\n",
    "\n",
    "# description_label이 긍정인지 부정인지 따라 dfPositiveDAta와 dfNegativeData에 나눠서 할당\n",
    "for i, data in dfData.iterrows():\n",
    "    title = data['title']\n",
    "    descripition = data['description']\n",
    "    title_label = data['title_label']\n",
    "    description_label = data['description_label']\n",
    "\n",
    "    if description_label == 1: # 긍정감성\n",
    "        dfTemp = pd.DataFrame([[title,descripition,description_label,title_label]],columns=dfPositiveData.columns)\n",
    "        dfTemp.columns = column_names\n",
    "        dfPositiveData = pd.concat([dfPositiveData, dfTemp])\n",
    "    else:   # 부정감성데이터\n",
    "        dfTemp = pd.DataFrame([[title,descripition,description_label,title_label]],columns=dfPositiveData.columns)\n",
    "        dfNegativeData = pd.concat([dfNegativeData,dfTemp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfPositiveData),len(dfNegativeData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍정 데이터에서 단어 추출\n",
    "posDescriptions = dfPositiveData['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posDescriptionsWords = []\n",
    "\n",
    "for d in posDescriptions:\n",
    "    posDescriptionsWords.append(okt.nouns(d))   # 명사 형태소만 추출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPosDescWords = []\n",
    "\n",
    "for d in posDescriptionsWords:\n",
    "    d2 = [w for w in d if len(w) > 1]   # 글자길이가 1보다 큰것만 추출\n",
    "    finalPosDescWords.append(' '.join(d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPosDescWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TF-IDF기반 단어별 출현빈도 계산\n",
    "posTfidf =  TfidfVectorizer(tokenizer=oktToken,min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posDtm =  posTfidf.fit_transform(finalPosDescWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posVocas = dict()\n",
    "for i, word in enumerate(posTfidf.get_feature_names_out()):\n",
    "   posVocas[word] = posDtm.getcol(i).sum() # 해당 단어의 빈도수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈도수가 높은 것 부터 정렬\n",
    "posWord = sorted(posVocas.items(), key=(lambda x : x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차트 라이브러리 등록\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 깨짐 문제 해결\n",
    "from matplotlib import rcParams, font_manager, rc\n",
    "\n",
    "font_path = 'C:/Windows/Fonts/malgun.ttf'\n",
    "font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font',family=font)\n",
    "rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max = 15\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.bar(range(max),[i[1] for i in posWord[:max]], color='blue')\n",
    "plt.title('네이버 긍정뉴스 단어 상위 15개', fontsize=14)\n",
    "plt.xlabel('단어', fontsize=12)\n",
    "plt.ylabel('빈도수',fontsize=12)\n",
    "# x축 단어 표시\n",
    "plt.xticks(range(max),[i[0] for i in posWord[:max]])\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
